{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "target = iris.target\n",
    "data = pd.DataFrame(iris.data,columns=iris.feature_names)\n",
    "\n",
    "\n",
    "data.columns = ['sepal_length','sepal_width','petal_length','petal_width']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(123)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.33, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Example = data.copy()\n",
    "Example['Label'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_train['label'] = y_train\n",
    "train_df = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_test['label'] = y_test\n",
    "test_df = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_purity(data):\n",
    "    \n",
    "    '''\n",
    "    looks if there is only one class\n",
    "    '''\n",
    "    \n",
    "    label = data[:,-1]\n",
    "    #returns array of our unique labels\n",
    "    unique_classes = np.unique(label)\n",
    "    \n",
    "    if len(unique_classes)==1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_purity(train_df[train_df['petal_length']>7].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data(data):\n",
    "    \n",
    "    #outputs the majority class of the dataset\n",
    "    \n",
    "    label = data[:,-1]\n",
    "    unique_classes, counts_of_unique_classes = np.unique(label,return_counts=True)\n",
    "\n",
    "    index = counts_of_unique_classes.argmax()\n",
    "\n",
    "    classification = unique_classes[index]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return classification\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potential_splits(data):\n",
    "    potential_splits = {}\n",
    "    _, n_columns = data.shape\n",
    "\n",
    "    for column_index in range(n_columns-1):\n",
    "        \n",
    "        values = data[:, column_index]\n",
    "        univalues = np.unique(values)\n",
    "        \n",
    "        potential_splits[column_index] = univalues\n",
    "        \n",
    "    \n",
    "    return potential_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "potential_splits = get_potential_splits(train_df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, split_column, split_value):\n",
    "    \n",
    "    \n",
    "    \n",
    "    split_column_values = data[:, split_column]\n",
    "    \n",
    "    type_of_feature = FEATURE_TYPES[split_column]\n",
    "    if type_of_feature == 'continuous':\n",
    "    \n",
    "        data_below = data[split_column_values <=split_value]\n",
    "        data_above = data[split_column_values >split_value]\n",
    "\n",
    "    else:\n",
    "        data_below = data[split_column_values ==split_value]\n",
    "        data_above = data[split_column_values !=split_value]\n",
    "        \n",
    "    \n",
    "    return data_below, data_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_column = 6\n",
    "\n",
    "split_value = 'C'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_below, data_above = split_data(train_df.values,split_column,split_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C'], dtype=object)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data_below[:, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowest Overall Entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(data):\n",
    "    label_column = data[:,-1]\n",
    "    ##determine probabilities of the classes\n",
    "\n",
    "    #count up the number of samples in each label\n",
    "    _,counts = np.unique(label_column,return_counts=True)\n",
    "    \n",
    "    #convert the count to the probability of a value falling into a certain class label\n",
    "    probabilities = counts/counts.sum()\n",
    "\n",
    "    \n",
    "    entropy = sum(probabilities * -np.log2(probabilities))\n",
    "\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overall_entropy(data_below,data_above):\n",
    "    \n",
    "    \n",
    "    n_data_points = len(data_below) + len(data_above)\n",
    "\n",
    "\n",
    "    #samples below the line\n",
    "    p_data_below = len(data_below)/n_data_points\n",
    "\n",
    "    #samples above the line\n",
    "    p_data_above = len(data_above)/n_data_points\n",
    "\n",
    "    overall_entropy = (p_data_below * calculate_entropy(data_below)\n",
    "\n",
    "                      +p_data_above * calculate_entropy(data_above))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    return overall_entropy\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the splits that results in the lowest overall entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_best_split(data, potential_splits):\n",
    "    \n",
    "    overall_entropy = 999\n",
    "\n",
    "\n",
    "    for column_index in potential_splits:\n",
    "        \n",
    "        #print(COLUMN_HEADERS[column_index], \"-\", len(np.unique(data[:, column_index])))\n",
    "        \n",
    "        for value in potential_splits[column_index]:\n",
    "            data_below, data_above = split_data(data,split_column=column_index,split_value=value)\n",
    "\n",
    "            current_overall_entropy = calculate_overall_entropy(data_below,data_above)\n",
    "\n",
    "            if current_overall_entropy <= overall_entropy:\n",
    "\n",
    "                overall_entropy=current_overall_entropy\n",
    "\n",
    "\n",
    "                best_split_column = column_index\n",
    "\n",
    "                best_split_value = value\n",
    "                \n",
    "                \n",
    "    return best_split_column,best_split_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_splits = get_potential_splits(Example.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1.9)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "determine_best_split(Example.values,potential_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_type_of_feature(data):\n",
    "    feature_types = []\n",
    "    n_unique_values_threshold = 15\n",
    "    for column in data.columns:\n",
    "        unique_vals = data[column].unique()\n",
    "        example_value = unique_vals[0]\n",
    "        \n",
    "        if type(example_value) == str or (len(unique_vals)<= n_unique_values_threshold):\n",
    "            feature_types.append(\"categorical\")\n",
    "        else:\n",
    "            feature_types.append(\"continuous\")\n",
    "    return feature_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['categorical', 'categorical', 'continuous', 'categorical', 'categorical', 'continuous', 'categorical', 'categorical']"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURE_TYPES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sub_tree = {question: [yes_answer, no_answer]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DecisionTreeAlgo(df, counter=0, min_samples=2, max_depth=5):\n",
    "    \n",
    "    \"\"\"\n",
    "    minimum sample size: the minimum number of sampels a node must contain in\n",
    "    order to consider splitting.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # data preparations\n",
    "    \n",
    "    if counter == 0:\n",
    "        \n",
    "        global COLUMN_HEADERS, FEATURE_TYPES\n",
    "        \n",
    "        \n",
    "        COLUMN_HEADERS = df.columns\n",
    "        FEATURE_TYPES = determine_type_of_feature(df)\n",
    "        \n",
    "        data = df.values\n",
    "    else:\n",
    "        \n",
    "        data = df\n",
    "        \n",
    "        \n",
    "    # base case for recusive function\n",
    "    if (check_purity(data)) or (len(data)< min_samples) or (counter==max_depth):\n",
    "        #return our prediction\n",
    "        classification = classify_data(data)\n",
    "        return classification\n",
    "    \n",
    "    \n",
    "    #recursive section\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "        \n",
    "        # run helper functions\n",
    "        \n",
    "        potential_splits = get_potential_splits(data)\n",
    "  \n",
    "            \n",
    "        #find lowest overall entropy\n",
    "        \n",
    "        split_column, split_value = determine_best_split(data, potential_splits)\n",
    "        \n",
    "        \n",
    "        data_below, data_above = split_data(data, split_column, split_value)\n",
    "        \n",
    "        \n",
    "        #check for empty data\n",
    "        if len(data_below) == 0 or len(data_above)==0:\n",
    "            classification = classify_data(data)\n",
    "            return classification\n",
    "        \n",
    "        \n",
    "        #instantiate sub-tree\n",
    "        feature_name = COLUMN_HEADERS[split_column]\n",
    "        \n",
    "        type_of_feature = FEATURE_TYPES[split_column]\n",
    "        if type_of_feature == 'continuous':\n",
    "            question  = \"{} <= {}\".format(feature_name,split_value)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            question  = \"{} == {}\".format(feature_name,split_value)\n",
    "\n",
    "        \n",
    "        sub_tree = {question: []}\n",
    "        \n",
    "        \n",
    "        #find answers\n",
    "        \n",
    "        yes_answer = DecisionTreeAlgo(data_below, counter, min_samples,max_depth)\n",
    "        \n",
    "        \n",
    "        no_answer = DecisionTreeAlgo(data_above, counter, min_samples,max_depth)\n",
    "        \n",
    "        if yes_answer == no_answer:\n",
    "            sub_tree = yes_answer\n",
    "        else:\n",
    "            \n",
    "        \n",
    "            sub_tree[question].append(yes_answer)\n",
    "            sub_tree[question].append(no_answer)\n",
    "        \n",
    "        \n",
    "        return sub_tree\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tree = DecisionTreeAlgo(train_df,min_samples=5,max_depth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(example, tree):\n",
    "    question = list(tree.keys())[0]\n",
    "\n",
    "    feature_name, comparison, value = question.split()\n",
    "\n",
    "    # ask question\n",
    "    \n",
    "    if comparison == \"<=\":\n",
    "        if example[feature_name] <= float(value):\n",
    "            answer = tree[question][0] \n",
    "        else:\n",
    "            answer = tree[question][1] \n",
    "            \n",
    "    else:\n",
    "        if str(example[feature_name]) == value:\n",
    "            answer = tree[question][0] \n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "        \n",
    "        \n",
    "\n",
    "    #base case    \n",
    "    if not isinstance(answer, dict):\n",
    "        return(answer)\n",
    "    else:\n",
    "\n",
    "        residual_tree = answer\n",
    "        return predict(example,residual_tree) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(example,tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(df,tree):\n",
    "    \n",
    "    df['classification'] = df.apply(predict, axis=1, args=(tree,))\n",
    "    \n",
    "    df['classification_correct'] = df.classification == df.label\n",
    "    \n",
    "    \n",
    "    accuracy = df.classification_correct.mean()\n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8271186440677966"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_accuracy(test_df,tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass                         3\n",
       "Sex                         male\n",
       "Age                           39\n",
       "SibSp                          1\n",
       "Parch                          5\n",
       "Fare                      31.275\n",
       "Embarked                       S\n",
       "label                          0\n",
       "classification                 0\n",
       "classification_correct      True\n",
       "Name: 13, dtype: object"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 6 is out of bounds for axis 1 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-325-76882d451e8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msplit_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msplit_value3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5.35\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdata_below\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_above\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mExample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit_column\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdata_belowsplit2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_abovesplit2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mExample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit_column\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-306-0e2e07212f9b>\u001b[0m in \u001b[0;36msplit_data\u001b[0;34m(data, split_column, split_value)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0msplit_column_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtype_of_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFEATURE_TYPES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 6 is out of bounds for axis 1 with size 5"
     ]
    }
   ],
   "source": [
    "split_column2 = 3\n",
    "split_value2 = 1.75\n",
    "split_value = 0.8\n",
    "split_value3 = 5.35\n",
    "data_below, data_above = split_data(Example.values,split_column,split_value)\n",
    "data_belowsplit2, data_abovesplit2 = split_data(Example.values,split_column,split_value)\n",
    "\n",
    "\n",
    "\n",
    "plotting_df = pd.DataFrame(data_belowsplit2,columns=train_df.columns)\n",
    "\n",
    "sns.lmplot(data=train_df,x='petal_width',y='petal_length',fit_reg=False,size=6,aspect=1.5,\n",
    "          hue='label')\n",
    "plt.vlines(x=split_value2,ymin=1,ymax=split_value3)\n",
    "plt.vlines(x=split_value,ymin=1,ymax=7)\n",
    "plt.hlines(y=split_value3,xmin=split_value,xmax=split_value2)\n",
    "\n",
    "plt.title('Petal Leaves')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/Users/Matt/Documents/Intro To Stat Learning/data/titanic (1)/train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label = train['Survived']\n",
    "train = train.drop(['PassengerId','Survived','Name','Ticket','Cabin'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "median_Age = train['Age'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna({\"Age\":median_Age,\"Embarked\":'S'})\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, label, test_size=0.33, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_df = X_train\n",
    "train_df['label'] = y_train\n",
    "\n",
    "\n",
    "test_df = X_test\n",
    "test_df['label'] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision With Categories Tree Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sex == male': [{'Age <= 12.0': [{'Fare <= 26.0': [1,\n",
      "                                                    {'Pclass == 3': [0,\n",
      "                                                                     1]}]},\n",
      "                                  {'Pclass == 1': [{'Fare <= 26.0': [0,\n",
      "                                                                     {'Age <= 38.0': [1,\n",
      "                                                                                      0]}]},\n",
      "                                                   0]}]},\n",
      "                 {'Pclass == 3': [{'Fare <= 24.15': [{'Age <= 36.0': [{'Fare <= 8.0292': [1,\n",
      "                                                                                          0]},\n",
      "                                                                      0]},\n",
      "                                                     {'Age <= 5.0': [1,\n",
      "                                                                     0]}]},\n",
      "                                  {'Fare <= 26.0': [{'Age <= 36.0': [1,\n",
      "                                                                     {'Age <= 55.0': [1,\n",
      "                                                                                      0]}]},\n",
      "                                                    {'Age <= 2.0': [0,\n",
      "                                                                    1]}]}]}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "tree = DecisionTreeAlgo(train_df,min_samples=5,max_depth=5)\n",
    "pprint(tree, width=50,depth=10)\n",
    "\n",
    "\n",
    "calculate_accuracy(test_df,tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
