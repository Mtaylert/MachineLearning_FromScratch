{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "target = iris.target\n",
    "data = pd.DataFrame(iris.data,columns=iris.feature_names)\n",
    "\n",
    "\n",
    "data.columns = ['sepal_length','sepal_width','petal_length','petal_width']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(123)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.33, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Example = data.copy()\n",
    "Example['Label'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_train['label'] = y_train\n",
    "train_df = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_test['label'] = y_test\n",
    "test_df = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_purity(data):\n",
    "    \n",
    "    '''\n",
    "    looks if there is only one class\n",
    "    '''\n",
    "    \n",
    "    label = data[:,-1]\n",
    "    #returns array of our unique labels\n",
    "    unique_classes = np.unique(label)\n",
    "    \n",
    "    if len(unique_classes)==1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_purity(train_df[train_df['petal_length']>7].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data(data):\n",
    "    \n",
    "    #outputs the majority class of the dataset\n",
    "    \n",
    "    label = data[:,-1]\n",
    "    unique_classes, counts_of_unique_classes = np.unique(label,return_counts=True)\n",
    "\n",
    "    index = counts_of_unique_classes.argmax()\n",
    "\n",
    "    classification = unique_classes[index]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return classification\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potential_splits(data):\n",
    "    potential_splits = {}\n",
    "    _, n_columns = data.shape\n",
    "\n",
    "    for column_index in range(n_columns-1):\n",
    "        \n",
    "        values = data[:, column_index]\n",
    "        univalues = np.unique(values)\n",
    "        \n",
    "        potential_splits[column_index] = univalues\n",
    "        \n",
    "    \n",
    "    return potential_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "potential_splits = get_potential_splits(train_df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, split_column, split_value):\n",
    "    \n",
    "    \n",
    "    \n",
    "    split_column_values = data[:, split_column]\n",
    "    \n",
    "    type_of_feature = FEATURE_TYPES[split_column]\n",
    "    if type_of_feature == 'continuous':\n",
    "    \n",
    "        data_below = data[split_column_values <=split_value]\n",
    "        data_above = data[split_column_values >split_value]\n",
    "\n",
    "    else:\n",
    "        data_below = data[split_column_values ==split_value]\n",
    "        data_above = data[split_column_values !=split_value]\n",
    "        \n",
    "    \n",
    "    return data_below, data_above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowest Overall Entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(data):\n",
    "    label_column = data[:,-1]\n",
    "    ##determine probabilities of the classes\n",
    "\n",
    "    #count up the number of samples in each label\n",
    "    _,counts = np.unique(label_column,return_counts=True)\n",
    "    \n",
    "    #convert the count to the probability of a value falling into a certain class label\n",
    "    probabilities = counts/counts.sum()\n",
    "\n",
    "    \n",
    "    entropy = sum(probabilities * -np.log2(probabilities))\n",
    "\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overall_entropy(data_below,data_above):\n",
    "    \n",
    "    \n",
    "    n_data_points = len(data_below) + len(data_above)\n",
    "\n",
    "\n",
    "    #samples below the line\n",
    "    p_data_below = len(data_below)/n_data_points\n",
    "\n",
    "    #samples above the line\n",
    "    p_data_above = len(data_above)/n_data_points\n",
    "\n",
    "    overall_entropy = (p_data_below * calculate_entropy(data_below)\n",
    "\n",
    "                      +p_data_above * calculate_entropy(data_above))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    return overall_entropy\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the splits that results in the lowest overall entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_best_split(data, potential_splits):\n",
    "    \n",
    "    overall_entropy = 999\n",
    "\n",
    "\n",
    "    for column_index in potential_splits:\n",
    "        \n",
    "        #print(COLUMN_HEADERS[column_index], \"-\", len(np.unique(data[:, column_index])))\n",
    "        \n",
    "        for value in potential_splits[column_index]:\n",
    "            data_below, data_above = split_data(data,split_column=column_index,split_value=value)\n",
    "\n",
    "            current_overall_entropy = calculate_overall_entropy(data_below,data_above)\n",
    "\n",
    "            if current_overall_entropy <= overall_entropy:\n",
    "\n",
    "                overall_entropy=current_overall_entropy\n",
    "\n",
    "\n",
    "                best_split_column = column_index\n",
    "\n",
    "                best_split_value = value\n",
    "                \n",
    "                \n",
    "    return best_split_column,best_split_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_splits = get_potential_splits(Example.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 0.6)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "determine_best_split(Example.values,potential_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_type_of_feature(data):\n",
    "    feature_types = []\n",
    "    n_unique_values_threshold = 15\n",
    "    for column in data.columns:\n",
    "        unique_vals = data[column].unique()\n",
    "        example_value = unique_vals[0]\n",
    "        \n",
    "        if type(example_value) == str or (len(unique_vals)<= n_unique_values_threshold):\n",
    "            feature_types.append(\"categorical\")\n",
    "        else:\n",
    "            feature_types.append(\"continuous\")\n",
    "    return feature_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['continuous', 'continuous', 'continuous', 'continuous', 'categorical']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURE_TYPES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sub_tree = {question: [yes_answer, no_answer]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DecisionTreeAlgo(df, counter=0, min_samples=2, max_depth=5):\n",
    "    \n",
    "    \"\"\"\n",
    "    minimum sample size: the minimum number of sampels a node must contain in\n",
    "    order to consider splitting.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # data preparations\n",
    "    \n",
    "    if counter == 0:\n",
    "        \n",
    "        global COLUMN_HEADERS, FEATURE_TYPES\n",
    "        \n",
    "        \n",
    "        COLUMN_HEADERS = df.columns\n",
    "        FEATURE_TYPES = determine_type_of_feature(df)\n",
    "        \n",
    "        data = df.values\n",
    "    else:\n",
    "        \n",
    "        data = df\n",
    "        \n",
    "        \n",
    "    # base case for recusive function\n",
    "    if (check_purity(data)) or (len(data)< min_samples) or (counter==max_depth):\n",
    "        #return our prediction\n",
    "        classification = classify_data(data)\n",
    "        return classification\n",
    "    \n",
    "    \n",
    "    #recursive section\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "        \n",
    "        # run helper functions\n",
    "        \n",
    "        potential_splits = get_potential_splits(data)\n",
    "  \n",
    "            \n",
    "        #find lowest overall entropy\n",
    "        \n",
    "        split_column, split_value = determine_best_split(data, potential_splits)\n",
    "        \n",
    "        \n",
    "        data_below, data_above = split_data(data, split_column, split_value)\n",
    "        \n",
    "        \n",
    "        #check for empty data\n",
    "        if len(data_below) == 0 or len(data_above)==0:\n",
    "            classification = classify_data(data)\n",
    "            return classification\n",
    "        \n",
    "        \n",
    "        #instantiate sub-tree\n",
    "        feature_name = COLUMN_HEADERS[split_column]\n",
    "        \n",
    "        type_of_feature = FEATURE_TYPES[split_column]\n",
    "        if type_of_feature == 'continuous':\n",
    "            question  = \"{} <= {}\".format(feature_name,split_value)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            question  = \"{} == {}\".format(feature_name,split_value)\n",
    "\n",
    "        \n",
    "        sub_tree = {question: []}\n",
    "        \n",
    "        \n",
    "        #find answers\n",
    "        \n",
    "        yes_answer = DecisionTreeAlgo(data_below, counter, min_samples,max_depth)\n",
    "        \n",
    "        \n",
    "        no_answer = DecisionTreeAlgo(data_above, counter, min_samples,max_depth)\n",
    "        \n",
    "        if yes_answer == no_answer:\n",
    "            sub_tree = yes_answer\n",
    "        else:\n",
    "            \n",
    "        \n",
    "            sub_tree[question].append(yes_answer)\n",
    "            sub_tree[question].append(no_answer)\n",
    "        \n",
    "        \n",
    "        return sub_tree\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tree = DecisionTreeAlgo(train_df,min_samples=5,max_depth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(example, tree):\n",
    "    question = list(tree.keys())[0]\n",
    "\n",
    "    feature_name, comparison, value = question.split()\n",
    "\n",
    "    # ask question\n",
    "    \n",
    "    if comparison == \"<=\":\n",
    "        if example[feature_name] <= float(value):\n",
    "            answer = tree[question][0] \n",
    "        else:\n",
    "            answer = tree[question][1] \n",
    "            \n",
    "    else:\n",
    "        if str(example[feature_name]) == value:\n",
    "            answer = tree[question][0] \n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "        \n",
    "        \n",
    "\n",
    "    #base case    \n",
    "    if not isinstance(answer, dict):\n",
    "        return(answer)\n",
    "    else:\n",
    "\n",
    "        residual_tree = answer\n",
    "        return predict(example,residual_tree) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'example' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-89992b8e2356>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'example' is not defined"
     ]
    }
   ],
   "source": [
    "predict(example,tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(df,tree):\n",
    "    \n",
    "    df['classification'] = df.apply(predict, axis=1, args=(tree,))\n",
    "    \n",
    "    df['classification_correct'] = df.classification == df.label\n",
    "    \n",
    "    \n",
    "    accuracy = df.classification_correct.mean()\n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_accuracy(test_df,tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "0             5.1          3.5           1.4          0.2\n",
       "1             4.9          3.0           1.4          0.2\n",
       "2             4.7          3.2           1.3          0.2\n",
       "3             4.6          3.1           1.5          0.2\n",
       "4             5.0          3.6           1.4          0.2\n",
       "5             5.4          3.9           1.7          0.4\n",
       "6             4.6          3.4           1.4          0.3\n",
       "7             5.0          3.4           1.5          0.2\n",
       "8             4.4          2.9           1.4          0.2\n",
       "9             4.9          3.1           1.5          0.1\n",
       "10            5.4          3.7           1.5          0.2\n",
       "11            4.8          3.4           1.6          0.2\n",
       "12            4.8          3.0           1.4          0.1\n",
       "13            4.3          3.0           1.1          0.1\n",
       "14            5.8          4.0           1.2          0.2\n",
       "15            5.7          4.4           1.5          0.4\n",
       "16            5.4          3.9           1.3          0.4\n",
       "17            5.1          3.5           1.4          0.3\n",
       "18            5.7          3.8           1.7          0.3\n",
       "19            5.1          3.8           1.5          0.3\n",
       "20            5.4          3.4           1.7          0.2\n",
       "21            5.1          3.7           1.5          0.4\n",
       "22            4.6          3.6           1.0          0.2\n",
       "23            5.1          3.3           1.7          0.5\n",
       "24            4.8          3.4           1.9          0.2\n",
       "25            5.0          3.0           1.6          0.2\n",
       "26            5.0          3.4           1.6          0.4\n",
       "27            5.2          3.5           1.5          0.2\n",
       "28            5.2          3.4           1.4          0.2\n",
       "29            4.7          3.2           1.6          0.2\n",
       "..            ...          ...           ...          ...\n",
       "120           6.9          3.2           5.7          2.3\n",
       "121           5.6          2.8           4.9          2.0\n",
       "122           7.7          2.8           6.7          2.0\n",
       "123           6.3          2.7           4.9          1.8\n",
       "124           6.7          3.3           5.7          2.1\n",
       "125           7.2          3.2           6.0          1.8\n",
       "126           6.2          2.8           4.8          1.8\n",
       "127           6.1          3.0           4.9          1.8\n",
       "128           6.4          2.8           5.6          2.1\n",
       "129           7.2          3.0           5.8          1.6\n",
       "130           7.4          2.8           6.1          1.9\n",
       "131           7.9          3.8           6.4          2.0\n",
       "132           6.4          2.8           5.6          2.2\n",
       "133           6.3          2.8           5.1          1.5\n",
       "134           6.1          2.6           5.6          1.4\n",
       "135           7.7          3.0           6.1          2.3\n",
       "136           6.3          3.4           5.6          2.4\n",
       "137           6.4          3.1           5.5          1.8\n",
       "138           6.0          3.0           4.8          1.8\n",
       "139           6.9          3.1           5.4          2.1\n",
       "140           6.7          3.1           5.6          2.4\n",
       "141           6.9          3.1           5.1          2.3\n",
       "142           5.8          2.7           5.1          1.9\n",
       "143           6.8          3.2           5.9          2.3\n",
       "144           6.7          3.3           5.7          2.5\n",
       "145           6.7          3.0           5.2          2.3\n",
       "146           6.3          2.5           5.0          1.9\n",
       "147           6.5          3.0           5.2          2.0\n",
       "148           6.2          3.4           5.4          2.3\n",
       "149           5.9          3.0           5.1          1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1, 'Petal Leaves')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 690.375x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "split_column2 = 3\n",
    "split_value2 = 1.75\n",
    "split_value = 0.8\n",
    "split_value3 = 5.35\n",
    "#data_below, data_above = split_data(Example.values,split_column,split_value)\n",
    "data_belowsplit2, data_abovesplit2 = split_data(data.values,split_column2,split_value2)\n",
    "\n",
    "\n",
    "\n",
    "plotting_df = pd.DataFrame(data_belowsplit2,columns=data.columns)\n",
    "\n",
    "sns.lmplot(data=train_df,x='petal_width',y='petal_length',fit_reg=False,size=6,aspect=1.5,\n",
    "          hue='label')\n",
    "plt.vlines(x=split_value2,ymin=1,ymax=split_value3)\n",
    "\n",
    "plt.vlines(x=split_value,ymin=1,ymax=7)\n",
    "plt.hlines(y=split_value3,xmin=split_value,xmax=split_value2)\n",
    "\n",
    "plt.title('Petal Leaves')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/Users/Matt/Documents/Intro To Stat Learning/data/titanic (1)/train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label = train['Survived']\n",
    "train = train.drop(['PassengerId','Survived','Name','Ticket','Cabin'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "median_Age = train['Age'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna({\"Age\":median_Age,\"Embarked\":'S'})\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, label, test_size=0.33, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_df = X_train\n",
    "train_df['label'] = y_train\n",
    "\n",
    "\n",
    "test_df = X_test\n",
    "test_df['label'] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision With Categories Tree Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sex == male': [{'Age <= 12.0': [{'Fare <= 26.0': [1,\n",
      "                                                    {'Pclass == 3': [0,\n",
      "                                                                     1]}]},\n",
      "                                  {'Pclass == 1': [{'Fare <= 26.0': [0,\n",
      "                                                                     {'Age <= 38.0': [1,\n",
      "                                                                                      0]}]},\n",
      "                                                   0]}]},\n",
      "                 {'Pclass == 3': [{'Fare <= 24.15': [{'Age <= 36.0': [{'Fare <= 8.0292': [1,\n",
      "                                                                                          0]},\n",
      "                                                                      0]},\n",
      "                                                     {'Age <= 5.0': [1,\n",
      "                                                                     0]}]},\n",
      "                                  {'Fare <= 26.0': [{'Age <= 36.0': [1,\n",
      "                                                                     {'Age <= 55.0': [1,\n",
      "                                                                                      0]}]},\n",
      "                                                    {'Age <= 2.0': [0,\n",
      "                                                                    1]}]}]}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "tree = DecisionTreeAlgo(train_df,min_samples=5,max_depth=5)\n",
    "pprint(tree, width=50,depth=10)\n",
    "\n",
    "\n",
    "calculate_accuracy(test_df,tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
